{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Prediction: Kaggle Playground Series S5E12\n",
    "\n",
    "**TL;DR (Too Long; Didn't Read):** This notebook predicts whether a person has diabetes based on health metrics. We use an ensemble of three gradient boosting models. The key insight: only the last 22,000 training samples match the test distribution.\n",
    "\n",
    "## How This Notebook Was Created\n",
    "\n",
    "This entire project was built using [Claude Code](https://claude.com/claude-code), Anthropic's command-line interface for Claude. Here's what that process looked like:\n",
    "\n",
    "1. We asked Claude to find a good Kaggle competition\n",
    "2. Claude searched active competitions and recommended this one (tabular data, good for gradient boosting)\n",
    "3. We downloaded the data using the Kaggle CLI (Command Line Interface)\n",
    "4. Claude read the competition discussion forums (via Chrome extension) and extracted key insights\n",
    "5. Claude wrote Python scripts, ran experiments, and iterated based on results\n",
    "6. We submitted predictions directly from the terminal\n",
    "\n",
    "Everything below is the actual approach we used. No cherry-picking, no hiding failures.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is This Competition About?\n",
    "\n",
    "Kaggle hosts machine learning competitions. This one is part of the \"Playground Series\" - monthly competitions with synthetic (artificially generated) datasets. They're designed for learning and practice.\n",
    "\n",
    "**The Task:** Given health measurements for a person, predict whether they have been diagnosed with diabetes.\n",
    "\n",
    "**The Data:**\n",
    "- 700,000 training examples (people with known diabetes status)\n",
    "- 300,000 test examples (people we need to predict)\n",
    "- 25 features (measurements about each person)\n",
    "\n",
    "**The Metric:** AUC-ROC (Area Under the Receiver Operating Characteristic Curve). This measures how well we can rank people by their likelihood of having diabetes. 1.0 = perfect, 0.5 = random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Critical Insight: Distribution Shift\n",
    "\n",
    "From reading the competition discussion forums, we learned something important:\n",
    "\n",
    "> The first ~678,000 training samples have a **different statistical distribution** than the test set. Only the **last ~22,000 training samples** match the test distribution.\n",
    "\n",
    "What does this mean in plain English?\n",
    "\n",
    "Imagine you're training to predict house prices in San Francisco, but 97% of your training data is actually from rural Kansas. If you validate your model on that Kansas data, you'll get misleading results. You need to validate on San Francisco data.\n",
    "\n",
    "That's exactly what's happening here. The competition organizers (deliberately or accidentally) created training data where most of it doesn't represent the test set. If we use all 700,000 samples for cross-validation, we get AUC scores around 0.727. But when we submit to the leaderboard, we get ~0.696.\n",
    "\n",
    "**The fix:** Only use the last 22,000 samples for validation. This gives us scores that actually predict leaderboard performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the packages we need and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install lightgbm xgboost catboost scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(f\"LightGBM: {lgb.__version__}\")\n",
    "print(f\"XGBoost: {xgb.__version__}\")\n",
    "print(f\"CatBoost: {cb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# If running on Kaggle, the data is at /kaggle/input/playground-series-s5e12/\n",
    "# If running locally, adjust the path\n",
    "\n",
    "DATA_PATH = \"/kaggle/input/playground-series-s5e12/\"\n",
    "# DATA_PATH = \"../data/playground-series-s5e12/\"  # For local runs\n",
    "\n",
    "train = pd.read_csv(f\"{DATA_PATH}train.csv\")\n",
    "test = pd.read_csv(f\"{DATA_PATH}test.csv\")\n",
    "sample_sub = pd.read_csv(f\"{DATA_PATH}sample_submission.csv\")\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Features\n",
    "\n",
    "Let's look at what information we have about each person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature types\n",
    "print(\"Columns and their types:\")\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Categories:**\n",
    "\n",
    "1. **Numerical (15 features):** Things we can measure with numbers\n",
    "   - `age` - How old the person is\n",
    "   - `bmi` - Body Mass Index (weight relative to height)\n",
    "   - `systolic_bp`, `diastolic_bp` - Blood pressure measurements\n",
    "   - `cholesterol_total`, `hdl_cholesterol`, `ldl_cholesterol` - Fat in blood\n",
    "   - `triglycerides` - Another type of blood fat\n",
    "   - Various lifestyle metrics (alcohol, activity, sleep, screen time, diet)\n",
    "\n",
    "2. **Categorical (6 features):** Categories/labels\n",
    "   - `gender`, `ethnicity`, `education_level`, `income_level`\n",
    "   - `smoking_status`, `employment_status`\n",
    "\n",
    "3. **Binary (3 features):** Yes/No flags\n",
    "   - `family_history_diabetes` - Does diabetes run in the family?\n",
    "   - `hypertension_history` - History of high blood pressure?\n",
    "   - `cardiovascular_history` - History of heart disease?\n",
    "\n",
    "4. **Target:** `diagnosed_diabetes` - What we're predicting (0 = no, 1 = yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Machine learning models need numbers, not text. We need to convert categorical features (like \"Male\"/\"Female\") into numbers (like 0/1).\n",
    "\n",
    "We use Label Encoding: assign a unique number to each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SEED = 42  # For reproducibility\n",
    "VAL_SIZE = 22000  # Last 22K samples for validation\n",
    "\n",
    "# Identify columns\n",
    "target_col = \"diagnosed_diabetes\"\n",
    "id_col = \"id\"\n",
    "feature_cols = [c for c in train.columns if c not in [target_col, id_col]]\n",
    "cat_cols = train[feature_cols].select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns: {cat_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode categorical features\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on both train and test to handle all possible values\n",
    "    combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
    "    le.fit(combined)\n",
    "    train[col] = le.transform(train[col].astype(str))\n",
    "    test[col] = le.transform(test[col].astype(str))\n",
    "\n",
    "# Prepare data\n",
    "X = train[feature_cols]\n",
    "y = train[target_col]\n",
    "X_test = test[feature_cols]\n",
    "test_ids = test[id_col]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Strategy\n",
    "\n",
    "This is the most important part. We split the data so the last 22,000 samples become our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split: last 22K for validation\n",
    "X_train = X.iloc[:-VAL_SIZE]\n",
    "y_train = y.iloc[:-VAL_SIZE]\n",
    "X_val = X.iloc[-VAL_SIZE:]\n",
    "y_val = y.iloc[-VAL_SIZE:]\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"\\nTarget rates:\")\n",
    "print(f\"  Training: {y_train.mean():.4f}\")\n",
    "print(f\"  Validation: {y_val.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "We train three different gradient boosting models and combine them:\n",
    "\n",
    "1. **LightGBM (Light Gradient Boosting Machine)** - Fast, memory-efficient\n",
    "2. **XGBoost (eXtreme Gradient Boosting)** - The classic choice\n",
    "3. **CatBoost (Categorical Boosting)** - Handles categories well\n",
    "\n",
    "### What is Gradient Boosting?\n",
    "\n",
    "Gradient boosting builds many simple decision trees, where each new tree tries to fix the mistakes of the previous trees. It's like having a team of experts where each one specializes in the cases the others got wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "print(\"Training LightGBM...\")\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 63,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_samples\": 50,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"n_estimators\": 2000,\n",
    "    \"random_state\": SEED,\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "lgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(200)],\n",
    ")\n",
    "\n",
    "lgb_val_pred = lgb_model.predict_proba(X_val)[:, 1]\n",
    "lgb_test_pred = lgb_model.predict_proba(X_test)[:, 1]\n",
    "print(f\"LightGBM Val AUC: {roc_auc_score(y_val, lgb_val_pred):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "\n",
    "# XGBoost needs categorical columns marked\n",
    "X_train_xgb = X_train.copy()\n",
    "X_val_xgb = X_val.copy()\n",
    "X_test_xgb = X_test.copy()\n",
    "\n",
    "for col in cat_cols:\n",
    "    X_train_xgb[col] = X_train_xgb[col].astype(\"category\")\n",
    "    X_val_xgb[col] = X_val_xgb[col].astype(\"category\")\n",
    "    X_test_xgb[col] = X_test_xgb[col].astype(\"category\")\n",
    "\n",
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_weight\": 50,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"n_estimators\": 2000,\n",
    "    \"random_state\": SEED,\n",
    "    \"enable_categorical\": True,\n",
    "    \"tree_method\": \"hist\",\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(**xgb_params)\n",
    "xgb_model.fit(X_train_xgb, y_train, eval_set=[(X_val_xgb, y_val)], verbose=200)\n",
    "\n",
    "xgb_val_pred = xgb_model.predict_proba(X_val_xgb)[:, 1]\n",
    "xgb_test_pred = xgb_model.predict_proba(X_test_xgb)[:, 1]\n",
    "print(f\"XGBoost Val AUC: {roc_auc_score(y_val, xgb_val_pred):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost\n",
    "print(\"Training CatBoost...\")\n",
    "\n",
    "cat_indices = [X_train.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "cb_params = {\n",
    "    \"objective\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"depth\": 8,\n",
    "    \"iterations\": 2000,\n",
    "    \"random_seed\": SEED,\n",
    "    \"verbose\": 200,\n",
    "    \"early_stopping_rounds\": 100,\n",
    "}\n",
    "\n",
    "cb_model = cb.CatBoostClassifier(**cb_params)\n",
    "cb_model.fit(X_train, y_train, eval_set=(X_val, y_val), cat_features=cat_indices)\n",
    "\n",
    "cb_val_pred = cb_model.predict_proba(X_val)[:, 1]\n",
    "cb_test_pred = cb_model.predict_proba(X_test)[:, 1]\n",
    "print(f\"CatBoost Val AUC: {roc_auc_score(y_val, cb_val_pred):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling\n",
    "\n",
    "Combining multiple models usually works better than any single model. We use Ridge regression to find optimal weights for each model's predictions.\n",
    "\n",
    "### Why does ensembling work?\n",
    "\n",
    "Different models make different mistakes. By averaging their predictions, errors tend to cancel out. It's like asking three doctors for a diagnosis instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal weights using Ridge regression\n",
    "val_preds = np.column_stack([lgb_val_pred, xgb_val_pred, cb_val_pred])\n",
    "test_preds = np.column_stack([lgb_test_pred, xgb_test_pred, cb_test_pred])\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(val_preds, y_val)\n",
    "\n",
    "weights = ridge.coef_\n",
    "weights = np.maximum(weights, 0)  # Keep non-negative\n",
    "weights = weights / weights.sum()  # Normalize to sum to 1\n",
    "\n",
    "print(\"Optimal weights:\")\n",
    "print(f\"  LightGBM: {weights[0]:.4f}\")\n",
    "print(f\"  XGBoost:  {weights[1]:.4f}\")\n",
    "print(f\"  CatBoost: {weights[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble predictions\n",
    "ensemble_val = val_preds @ weights\n",
    "ensemble_test = test_preds @ weights\n",
    "\n",
    "# Compare results\n",
    "print(\"\\nResults (Validation on last 22K samples):\")\n",
    "print(f\"  LightGBM:  {roc_auc_score(y_val, lgb_val_pred):.5f}\")\n",
    "print(f\"  XGBoost:   {roc_auc_score(y_val, xgb_val_pred):.5f}\")\n",
    "print(f\"  CatBoost:  {roc_auc_score(y_val, cb_val_pred):.5f}\")\n",
    "print(f\"  Ensemble:  {roc_auc_score(y_val, ensemble_val):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"diagnosed_diabetes\": ensemble_test,\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission saved!\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We Learned\n",
    "\n",
    "1. **Distribution shift matters.** Using the wrong validation set gave us misleading scores (0.727 vs 0.696 on leaderboard).\n",
    "\n",
    "2. **Read the discussions.** The insight about the last 22K samples came from community members analyzing the data.\n",
    "\n",
    "3. **Ensembles help.** Combining three gradient boosting models improved over any single model.\n",
    "\n",
    "4. **Simple approaches work.** We didn't need complex feature engineering. The key was getting the validation strategy right.\n",
    "\n",
    "## What We'd Try Next\n",
    "\n",
    "- Add neural network models (TabNet, FT-Transformer) for more diversity\n",
    "- Use the original dataset for target encoding features\n",
    "- Weighted sample refit (give higher weight to last 22K samples)\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook was created with Claude Code. The full project is at: https://github.com/bedwards/caggle*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
